{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfpl = tfp.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignore next to cells if you have already splitted your dataset, else add it to split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_dir = os.path.join('D:/Gugan/kaggle brain MRI dataset/')\n",
    "#output_dir = os.path.join('D:/Gugan/kaggle brain MRI dataset/splitted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitfolders.ratio(input_dir, output=output_dir, seed=1337, ratio=(.8, .2), group_prefix=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join('D:/second paper/kaggle brain MRI dataset/splitted/train/')\n",
    "test_dir = os.path.join('D:/second paper/kaggle brain MRI dataset/splitted/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_generator(train_parent_directory, test_parent_directory):\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "    test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_directory(train_parent_directory,\n",
    "                                  target_size = (300,300),\n",
    "                                  batch_size = 32,\n",
    "                                  class_mode = 'categorical',\n",
    "                                  subset='training')\n",
    " \n",
    "    \n",
    "    test_generator = test_datagen.flow_from_directory(test_parent_directory,\n",
    "                                 target_size=(300,300),\n",
    "                                 batch_size = 32,\n",
    "                                 class_mode = 'categorical')    \n",
    "    \n",
    "    return train_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 202 images belonging to 2 classes.\n",
      "Found 51 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator, test_generator = image_generator(train_dir, test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(train_generator))\n",
    "print(len(test_generator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple 4 layer CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 285, 285, 8)       6152      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 142, 142, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 140, 140, 32)      2336      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 70, 70, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 68, 68, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 34, 34, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               8389120   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 8,454,058\n",
      "Trainable params: 8,454,058\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(input_shape=(300,300,3), filters=8, kernel_size=16, activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(32, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(units=2, activation='softmax')\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor = \"val_accuracy\", min_delta = 0.01, patience = 15, mode = \"max\", restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=7,\n",
    "    validation_data = test_generator,\n",
    "    validation_steps = 2,\n",
    "      epochs=100,\n",
    "    callbacks = [callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def import_and_predict(image_data, label):\n",
    "    \n",
    "    #read image\n",
    "    img = cv2.imread(image_data)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n",
    "    \n",
    "    #show the image\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # resize and reshape the image\n",
    "    img_resize = (cv2.resize(img, dsize=(300, 300), interpolation=cv2.INTER_CUBIC))/255.\n",
    "    \n",
    "    img_reshape = img_resize[np.newaxis,...]\n",
    "    \n",
    "    #predict the image\n",
    "    prediction = model.predict(img_reshape)\n",
    "    print(prediction)\n",
    "    \n",
    "    label_prediction = label[np.argmax(prediction)]\n",
    "    \n",
    "    return label_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = os.listdir(test_dir)\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1_dir = os.path.join(test_dir+'yes/Y244.jpg')\n",
    "image1_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image2_dir = os.path.join(test_dir+'no/no 99.jpg')\n",
    "image2_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction1 = import_and_predict(image1_dir, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian CNN with Reparameterization layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_reparameterization_2  (None, 285, 285, 8)       12304     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 142, 142, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_reparameterization_3  (None, 111, 111, 8)       131088    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 55, 55, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 53, 53, 64)        4672      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               4719104   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_reparameterization_1 ( (None, 2)                 2052      \n",
      "_________________________________________________________________\n",
      "one_hot_categorical_1 (OneHo multiple                  0         \n",
      "=================================================================\n",
      "Total params: 4,906,148\n",
      "Trainable params: 4,906,148\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "divergence_fn = lambda q,p,_:tfd.kl_divergence(q,p)/3457\n",
    "\n",
    "model_bayes = Sequential([\n",
    "    \n",
    "    tfpl.Convolution2DReparameterization(input_shape=(300,300,3), filters=8, kernel_size=16, activation='relu',\n",
    "                                           kernel_prior_fn = tfpl.default_multivariate_normal_fn,\n",
    "                                           kernel_posterior_fn=tfpl.default_mean_field_normal_fn(is_singular=False),\n",
    "                                           kernel_divergence_fn = divergence_fn,\n",
    "                                           bias_prior_fn = tfpl.default_multivariate_normal_fn,\n",
    "                                           bias_posterior_fn=tfpl.default_mean_field_normal_fn(is_singular=False),\n",
    "                                           bias_divergence_fn = divergence_fn),\n",
    "    MaxPooling2D(2,2),\n",
    "    tfpl.Convolution2DReparameterization(input_shape=(300,300,3), filters=8, kernel_size=32, activation='relu',\n",
    "                                           kernel_prior_fn = tfpl.default_multivariate_normal_fn,\n",
    "                                           kernel_posterior_fn=tfpl.default_mean_field_normal_fn(is_singular=False),\n",
    "                                           kernel_divergence_fn = divergence_fn,\n",
    "                                           bias_prior_fn = tfpl.default_multivariate_normal_fn,\n",
    "                                           bias_posterior_fn=tfpl.default_mean_field_normal_fn(is_singular=False),\n",
    "                                           bias_divergence_fn = divergence_fn),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    tfpl.DenseReparameterization(units=tfpl.OneHotCategorical.params_size(2), activation=None,\n",
    "                                    kernel_prior_fn = tfpl.default_multivariate_normal_fn,\n",
    "                                    kernel_posterior_fn=tfpl.default_mean_field_normal_fn(is_singular=False),\n",
    "                                    kernel_divergence_fn = divergence_fn,\n",
    "                                    bias_prior_fn = tfpl.default_multivariate_normal_fn,\n",
    "                                    bias_posterior_fn=tfpl.default_mean_field_normal_fn(is_singular=False),\n",
    "                                    bias_divergence_fn = divergence_fn\n",
    "                                ),\n",
    "    tfpl.OneHotCategorical(5)\n",
    "    \n",
    "])\n",
    "model_bayes.summary()\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor = \"val_accuracy\", min_delta = 0.01, patience = 15, mode = \"max\", restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_log_likelihood(y_true, y_pred):\n",
    "    return -y_pred.log_prob(y_true)\n",
    "\n",
    "model_bayes.compile(loss = negative_log_likelihood,\n",
    "              optimizer = Adam(learning_rate=0.005),\n",
    "              metrics = ['accuracy'],\n",
    "              experimental_run_tf_function = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_bayes = model_bayes.fit(\n",
    "      train_generator,\n",
    "      epochs=300,\n",
    "      steps_per_epoch = 7,\n",
    "      validation_data = test_generator,\n",
    "      validation_steps = 2,\n",
    "      callbacks = [callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bayes.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_and_predict_bayes(image, true_label):\n",
    "\n",
    "    #read image\n",
    "    img = cv2.imread(image)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n",
    "    \n",
    "    #show the image\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    img_resize = (cv2.resize(img, dsize=(300, 300), interpolation=cv2.INTER_CUBIC))/255.\n",
    "    \n",
    "    predicted_probabilities = np.empty(shape=(300, 2))\n",
    "    \n",
    "    for i in range(300):\n",
    "        \n",
    "        predicted_probabilities[i] = model_bayes(img_resize[np.newaxis,...]).mean().numpy()[0]\n",
    "        \n",
    "    pct_2p5 = np.array([np.percentile(predicted_probabilities[:, i], 2.5) for i in range(2)])\n",
    "    pct_97p5 = np.array([np.percentile(predicted_probabilities[:, i], 97.5) for i in range(2)])\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    bar = ax.bar(np.arange(2), pct_97p5, color='red')\n",
    "    bar[true_label].set_color('green')\n",
    "    bar = ax.bar(np.arange(2), pct_2p5-0.02, color='white', linewidth=1, edgecolor='white')\n",
    "    ax.set_xticklabels([''] + [x for x in label])\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.set_ylabel('Probability')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_and_predict_bayes(image2_dir, label.index('no'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
